{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and split it into trainings, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_pickle('dataset.pkl')\n",
    "\n",
    "# Extract the validation data from the dataset\n",
    "val_data = data.loc[data.run >= 97].drop('run', axis=1)\n",
    "data = data.loc[data.run <= 96].drop('run', axis=1)\n",
    "\n",
    "# Split the remaining dataset into trainings and test data\n",
    "test_size=0.25\n",
    "train_complete = data[:int(len(data)*0.75)]\n",
    "test_complete = data[int(len(data)*0.75):]\n",
    "\n",
    "# Method to get data. The dataset can be reduced by a factor and the less important features can be dropped.\n",
    "def get_data(factor=1):\n",
    "\n",
    "    train = train_complete[:(len(train_complete)//factor)]\n",
    "    test = test_complete[:(len(test_complete)//factor)]\n",
    "    val = val_data[:(len(val_data)//factor)]\n",
    "    \n",
    "    print('Length trainings data:', len(train), 'Length test data:', len(test), 'Length validation data:', len(val), '\\n')\n",
    "    return train, test, val\n",
    "\n",
    "def get_columns():\n",
    "    return val_data.columns\n",
    "\n",
    "train, test, val = get_data()\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "forest_clf = joblib.load('models\\model_0043')\n",
    "\n",
    "train, test, val = get_data(factor=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the trainings, test and validation data\n",
    "factor = 1\n",
    "train, test, val = get_data(factor=factor)\n",
    "\n",
    "# Initialize the random forest classifier\n",
    "forest_clf = RandomForestClassifier(n_jobs=-1, max_features='auto', n_estimators=40,criterion='entropy')\n",
    "\n",
    "# Train the classifier on the trainings data\n",
    "forest_clf.fit(train.drop('y', axis=1), train.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print accuracy and F1-score for the test and validation data\n",
    "y_pred = forest_clf.predict(test.drop('y', axis=1))\n",
    "print('\\nAccuracy on test data:', accuracy_score(test.y, y_pred))\n",
    "print('F1-score on test data:', f1_score(test.y, y_pred))\n",
    "print('Precision on test data:', precision_score(test.y, y_pred))\n",
    "\n",
    "y_pred = forest_clf.predict(val.drop('y', axis=1))\n",
    "print('\\nAccurcay on validation data:', accuracy_score(val.y, y_pred))\n",
    "print('F1-score on validation data:', f1_score(val.y, y_pred))\n",
    "print('Precision on trainings data:', precision_score(val.y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(forest_clf, 'models\\model_0099')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the precision and recall for different thresholds and plots the precision-Recal curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions of the classifier as probabilities\n",
    "y_pred = np.transpose(forest_clf.predict_proba(val.drop('y', axis=1)))[1]\n",
    "\n",
    "# Compute precision, recall and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(val.y, y_pred)\n",
    "\n",
    "# Computes the area under curve from the precision and recall\n",
    "auc_score = auc(recall, precision)\n",
    "print('Area under curve:', auc_score)\n",
    "\n",
    "# Plot the precision-recall curves\n",
    "#plt.plot([1, 0], [0, 1], 'k--') \n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.plot(recall, precision, linestyle='-', label='Random Forest')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig('forest_precision_recall.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse and plot the feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieves the feature importance from the random forest and prints it featurewise\n",
    "importance = forest_clf.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v), '-', get_columns()[i])\n",
    "    pass\n",
    "\n",
    "ticks = [w.replace('cosAngleBetweenMomentumAndVertexVector', 'cosMomemtumVertex') for w in val.drop('y', axis=1).columns]\n",
    "ticks = [w.replace('_1', '') for w in ticks]\n",
    "labels = []\n",
    "first_photon, second_photon = [], []\n",
    "\n",
    "for i in range(len(ticks)):\n",
    "    if i % 2 != 0:\n",
    "        second_photon.append(importance[i])\n",
    "    else:\n",
    "        first_photon.append(importance[i])\n",
    "        labels.append(ticks[i])\n",
    "\n",
    "for i in range(len(first_photon)):\n",
    "    highest_index = i\n",
    "    for j in np.arange(i, len(first_photon)):\n",
    "        if first_photon[highest_index] < first_photon[j]:\n",
    "            highest_index = j\n",
    "            #print('hea')\n",
    "        #print(highest_index)\n",
    "    first_photon[i], first_photon[highest_index] = first_photon[highest_index], first_photon[i]\n",
    "    second_photon[i], second_photon[highest_index] = second_photon[highest_index], second_photon[i]\n",
    "    labels[i], labels[highest_index] = labels[highest_index], labels[i]\n",
    "        \n",
    "        \n",
    "bar_width = 0.8\n",
    "index = np.arange(0,len(first_photon)*2,2)\n",
    "opacity = 0.8\n",
    "\n",
    "color='g'\n",
    "\n",
    "plt.bar(index, first_photon, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='b',\n",
    "    label='First photon')\n",
    "\n",
    "plt.bar(index + bar_width, second_photon, bar_width,\n",
    "    alpha=opacity,\n",
    "    color='g',\n",
    "    label='Second photon')\n",
    "\n",
    "plt.xticks(index + bar_width / 2, labels, rotation=310, ha='left')\n",
    "\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Feature importance / a.u.')\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "\n",
    "plt.savefig('forest_feature_importance.pdf', format='pdf', bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [np.transpose(forest_clf.predict_proba(test.drop('y', axis=1)))[1], np.transpose(forest_clf.predict_proba(val.drop('y', axis=1)))[1], None]\n",
    "np.save('models/model_0043_data.npy', data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
