{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and split it into trainings, test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_pickle('dataset.pkl')\n",
    "\n",
    "# Extract the validation data from the dataset\n",
    "val_data = data.loc[data.run >= 97].drop('run', axis=1)\n",
    "data = data.loc[data.run <= 96].drop('run', axis=1)\n",
    "\n",
    "# Split the remaining dataset into trainings and test data\n",
    "# Split the remaining dataset into trainings and test data\n",
    "test_size=0.25\n",
    "train_complete = data[:int(len(data)*0.75)]\n",
    "test_complete = data[int(len(data)*0.75):]\n",
    "\n",
    "# Method to drop the less important features\n",
    "def drop_less_important(data_temp):\n",
    "    return data_temp.drop(['clusterAbsZernikeMoment40_1', 'clusterAbsZernikeMoment40_2', 'clusterAbsZernikeMoment51_1', 'clusterAbsZernikeMoment51_2', 'clusterLAT_1', 'clusterLAT_2','phi_1', 'phi_2','b2bPhi_1', 'b2bPhi_2','cosAngleBetweenMomentumAndVertexVectorInXYPlane_1', 'cosAngleBetweenMomentumAndVertexVectorInXYPlane_2','pRecoilPhi_1', 'pRecoilPhi_2'], axis=1, errors='ignore')\n",
    "\n",
    "# Method to get data. The dataset can be reduced by a factor and the less important features can be dropped.\n",
    "def get_data(factor=1, important_drop=False):\n",
    "\n",
    "    train = train_complete[:(len(train_complete)//factor)]\n",
    "    test = test_complete[:(len(test_complete)//factor)]\n",
    "    val = val_data[:(len(val_data)//factor)]\n",
    "\n",
    "    if important_drop:\n",
    "        train = drop_less_important(train)\n",
    "        test = drop_less_important(test)\n",
    "        val = drop_less_important(val)\n",
    "    \n",
    "    print('Length trainings data:', len(train), 'Length test data:', len(test), 'Length validation data:', len(val), '\\n')\n",
    "    return train, test, val\n",
    "\n",
    "def get_columns():\n",
    "    return val_data.columns\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the trainings, test and validation data\n",
    "factor = 1\n",
    "train, test, val = get_data(factor=factor, important_drop=False)\n",
    "\n",
    "# Define a dropout rate for the 'Dropout' layer\n",
    "rate = 0.2\n",
    "\n",
    "# Create the model\n",
    "tf.random.set_random_seed(42)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=((len(val.columns)-1),)),\n",
    "    keras.layers.Dense(512, activation='tanh'),\n",
    "    keras.layers.Dense(128, activation='tanh'),\n",
    "    keras.layers.Dense(32, activation='tanh'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "    \n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Set the parameters for the training\n",
    "num_of_epochs = 100\n",
    "batch_size = 1024\n",
    "\n",
    "# Use early stopping to interrupt the trainings process when the validatin loss starts do increase over a given number of epochs\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "# Train the network\n",
    "train_history = model.fit(train.drop('y', axis=1), train.y, epochs=num_of_epochs, verbose=1, batch_size=batch_size, validation_data=(val.drop('y', axis=1), val.y), callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the accuracy and loss during training, evaluate the model, print the F1-score and the best accuracy in the validation dataset over the whole trainings session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(loss, acc):\n",
    "    # Plot the trainings and accuracy history\n",
    "    \n",
    "    _, (ax1, ax2) = plt.subplots(2, sharex=True, figsize=(12,8))\n",
    "    \n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.plot(loss, '-')\n",
    "    \n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch Index')\n",
    "    ax2.plot(acc, '-')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training(train_history.history['loss'], train_history.history['acc'])\n",
    "plot_training(train_history.history['val_loss'], train_history.history['val_acc'])\n",
    "\n",
    "# Print accuracy and F1-score for the test and validation data\n",
    "y_pred = np.vectorize(round)(model.predict(test.drop('y', axis=1)))\n",
    "print('\\nAccuracy on test data:', accuracy_score(test.y, y_pred))\n",
    "print('F1-score on test data:', f1_score(test.y, y_pred))\n",
    "print('Precision on test data:', precision_score(test.y, y_pred))\n",
    "\n",
    "y_pred = np.vectorize(round)(model.predict(val.drop('y', axis=1)))\n",
    "print('\\nAccurcay on validation data:', accuracy_score(val.y, y_pred))\n",
    "print('F1-score on validation data:', f1_score(val.y, y_pred))\n",
    "print('Precision on validation data:', precision_score(val.y, y_pred))\n",
    "\n",
    "print('\\nHighest accuracy on the validation dataset during the trainings process:')\n",
    "print(max(train_history.history['val_acc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Precision-Recall curve and compute AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions of the classifier as probabilities\n",
    "y_pred = model.predict(val.drop('y', axis=1))\n",
    "\n",
    "# Compute precision, recall and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(val.y, y_pred)\n",
    "\n",
    "# Computes the area under curve from the precision and recall\n",
    "auc_score = auc(recall, precision)\n",
    "print('Area under curve:', auc_score)\n",
    "\n",
    "# Plot the precision-recall curves\n",
    "#plt.plot([1, 0], [0, 1], 'k--') \n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.plot(recall, precision, linestyle='-', label='Neural Network')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and load the trainings histroy and the predictions during testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'models/model_9999_data.npy'\n",
    "data = [model.predict(test.drop('y', axis=1)), model.predict(val.drop('y', axis=1)), train_history.history]\n",
    "np.save(filename, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
